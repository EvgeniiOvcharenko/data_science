{"cells":[{"cell_type":"markdown","metadata":{"id":"NlVC5j9gdd99"},"source":["# Наивный Байесовский Классификатор для классификации спам-сообщений"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"i35VBQfFdd-E"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["Прочитаем файл (разделителем здесь выступает символ табуляции)."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"A1b5QrS5dd-F","outputId":"ad0e2dbf-f406-41ae-8cda-9e043efb2f8b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                                SMS\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["sms_data = pd.read_csv('SMSSpamCollection.zip', header=None, sep='\\t', names=['Label', 'SMS'])\n","sms_data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Посмотрим, сколько объектов каждого класса присутствует в датасете."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p7_2JzUvdd-G","outputId":"6167fcf9-f386-48cf-b2fe-4ca8012835c1","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMS</th>\n","    </tr>\n","    <tr>\n","      <th>Label</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ham</th>\n","      <td>4825</td>\n","    </tr>\n","    <tr>\n","      <th>spam</th>\n","      <td>747</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        SMS\n","Label      \n","ham    4825\n","spam    747"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sms_data.groupby('Label').count()"]},{"cell_type":"markdown","metadata":{"id":"hQG2a4SVdd-H"},"source":["### Предобработка данных"]},{"cell_type":"markdown","metadata":{},"source":["Удаляем символы, не являющиеся буквами, приводим тексты SMS к нижнему регистру, разбиваем строки на слова."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T9c0M4vhdd-I"},"outputs":[],"source":["sms_data_clean = sms_data.copy()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Jd-UcYg6dd-I"},"outputs":[{"data":{"text/plain":["0    [go, until, jurong, point, crazy, available, o...\n","1                       [ok, lar, joking, wif, u, oni]\n","2    [free, entry, in, 2, a, wkly, comp, to, win, f...\n","3    [u, dun, say, so, early, hor, u, c, already, t...\n","4    [nah, i, don, t, think, he, goes, to, usf, he,...\n","Name: SMS, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\W+', ' ', regex=True)\n","\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.lower()\n","sms_data_clean['SMS'] = sms_data_clean['SMS'].str.split()\n","\n","sms_data_clean['SMS'].head()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"PZCmBLCLdd-L","outputId":"e37750a2-4124-4733-9bb2-0e7b057e4171","scrolled":true},"outputs":[{"data":{"text/plain":["Label\n","ham     86.593683\n","spam    13.406317\n","Name: count, dtype: float64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["sms_data_clean['Label'].value_counts() / sms_data_clean.shape[0] * 100"]},{"cell_type":"markdown","metadata":{"id":"50oksBrrdd-L"},"source":["### Разделение на обучающую и тестовую выборки"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_data = sms_data_clean.sample(frac=0.8, random_state=42)\n","test_data = sms_data_clean.drop(train_data.index)\n","\n","train_data = train_data.reset_index(drop=True)\n","test_data = test_data.reset_index(drop=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"WU_YwDxgdd-M","outputId":"d7897ce6-95c9-4be3-f269-5009666c7f3e"},"outputs":[{"data":{"text/plain":["Label\n","ham     86.698071\n","spam    13.301929\n","Name: count, dtype: float64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_data['Label'].value_counts() / train_data.shape[0] * 100"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"B_WG0yuqdd-M","outputId":"c3c9a44e-9ee8-42f4-d6b6-5522898cb267"},"outputs":[{"data":{"text/plain":["(4458, 2)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_data.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"fbrlnUxfdd-N","outputId":"2bdc65d7-0b76-4c28-dae7-d1fe620e6a59"},"outputs":[{"data":{"text/plain":["Label\n","ham     86.175943\n","spam    13.824057\n","Name: count, dtype: float64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_data['Label'].value_counts() / test_data.shape[0] * 100"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dHM1P3h2dd-N","outputId":"4b2a0eba-0468-4e7d-e1dd-f091728cdecc","scrolled":true},"outputs":[{"data":{"text/plain":["(1114, 2)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_data.shape"]},{"cell_type":"markdown","metadata":{},"source":["Мы видим, что и в обучающей, и в тестовой выборке содержится примерно 86-87% спама – как и в нашем оригинальном датасете."]},{"cell_type":"markdown","metadata":{"id":"CVmTrhNSdd-O"},"source":["### Список слов"]},{"cell_type":"markdown","metadata":{},"source":["Создаём список всех слов, встречающихся в обучающей выборке."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ahLFpWI3dd-O"},"outputs":[],"source":["vocabulary = list(set(train_data['SMS'].sum()))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"eSN6U0QLdd-O","outputId":"5dcb7d6f-900f-483c-e896-4ef69459dced"},"outputs":[{"data":{"text/plain":["['bcoz',\n"," '7oz',\n"," 'polys',\n"," 'gamestar',\n"," 'jod',\n"," 'sucks',\n"," 'companion',\n"," 'drunk',\n"," 'through']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["vocabulary[11:20]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"MegzBwCFdd-P","outputId":"fa6a956c-5602-4193-8925-6ecb43b5b719"},"outputs":[{"data":{"text/plain":["7816"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(vocabulary)"]},{"cell_type":"markdown","metadata":{"id":"xs_mok2wdd-P"},"source":["### Рассчитаем частоты слов"]},{"cell_type":"markdown","metadata":{},"source":["Для каждого SMS-сообщения посчитаем, сколько раз в нём встречается каждое слово."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"vER-xPhXdd-P"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>catch</th>\n","      <th>phoenix</th>\n","      <th>express</th>\n","      <th>maruti</th>\n","      <th>82324</th>\n","      <th>ovulate</th>\n","      <th>defer</th>\n","      <th>tog</th>\n","      <th>okors</th>\n","      <th>what</th>\n","      <th>...</th>\n","      <th>messenger</th>\n","      <th>amy</th>\n","      <th>konw</th>\n","      <th>significant</th>\n","      <th>property</th>\n","      <th>wesleys</th>\n","      <th>behave</th>\n","      <th>mcat</th>\n","      <th>wocay</th>\n","      <th>miwa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 7816 columns</p>\n","</div>"],"text/plain":["   catch  phoenix  express  maruti  82324  ovulate  defer  tog  okors  what   \n","0      0        0        0       0      0        0      0    0      0     0  \\\n","1      0        0        0       0      0        0      0    0      0     0   \n","2      0        0        0       0      0        0      0    0      0     0   \n","3      0        0        0       0      0        0      0    0      0     0   \n","4      0        0        0       0      0        0      0    0      0     0   \n","\n","   ...  messenger  amy  konw  significant  property  wesleys  behave  mcat   \n","0  ...          0    0     0            0         0        0       0     0  \\\n","1  ...          0    0     0            0         0        0       0     0   \n","2  ...          0    0     0            0         0        0       0     0   \n","3  ...          0    0     0            0         0        0       0     0   \n","4  ...          0    0     0            0         0        0       0     0   \n","\n","   wocay  miwa  \n","0      0     0  \n","1      0     0  \n","2      0     0  \n","3      0     0  \n","4      0     0  \n","\n","[5 rows x 7816 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["word_counts_per_sms = pd.DataFrame([\n","    [row[1].count(word) for word in vocabulary]\n","    for _, row in train_data.iterrows()], columns=vocabulary)\n","\n","word_counts_per_sms.head()"]},{"cell_type":"markdown","metadata":{},"source":["Добавим частоты каждого слова в обучающий датасет."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"dNc8Juygdd-P"},"outputs":[],"source":["train_data = pd.concat([train_data, word_counts_per_sms], axis=1)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"FxcXHWgqdd-Q","outputId":"cda89d7c-4596-4dc7-e274-01afb214c54c","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>catch</th>\n","      <th>phoenix</th>\n","      <th>express</th>\n","      <th>maruti</th>\n","      <th>82324</th>\n","      <th>ovulate</th>\n","      <th>defer</th>\n","      <th>tog</th>\n","      <th>...</th>\n","      <th>messenger</th>\n","      <th>amy</th>\n","      <th>konw</th>\n","      <th>significant</th>\n","      <th>property</th>\n","      <th>wesleys</th>\n","      <th>behave</th>\n","      <th>mcat</th>\n","      <th>wocay</th>\n","      <th>miwa</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>[squeeeeeze, this, is, christmas, hug, if, u, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>[and, also, i, ve, sorta, blown, him, off, a, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ham</td>\n","      <td>[mmm, thats, better, now, i, got, a, roast, do...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>[mm, have, some, kanji, dont, eat, anything, h...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>[so, there, s, a, ring, that, comes, with, the...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 7818 columns</p>\n","</div>"],"text/plain":["  Label                                                SMS  catch  phoenix   \n","0   ham  [squeeeeeze, this, is, christmas, hug, if, u, ...      0        0  \\\n","1   ham  [and, also, i, ve, sorta, blown, him, off, a, ...      0        0   \n","2   ham  [mmm, thats, better, now, i, got, a, roast, do...      0        0   \n","3   ham  [mm, have, some, kanji, dont, eat, anything, h...      0        0   \n","4   ham  [so, there, s, a, ring, that, comes, with, the...      0        0   \n","\n","   express  maruti  82324  ovulate  defer  tog  ...  messenger  amy  konw   \n","0        0       0      0        0      0    0  ...          0    0     0  \\\n","1        0       0      0        0      0    0  ...          0    0     0   \n","2        0       0      0        0      0    0  ...          0    0     0   \n","3        0       0      0        0      0    0  ...          0    0     0   \n","4        0       0      0        0      0    0  ...          0    0     0   \n","\n","   significant  property  wesleys  behave  mcat  wocay  miwa  \n","0            0         0        0       0     0      0     0  \n","1            0         0        0       0     0      0     0  \n","2            0         0        0       0     0      0     0  \n","3            0         0        0       0     0      0     0  \n","4            0         0        0       0     0      0     0  \n","\n","[5 rows x 7818 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"markdown","metadata":{"id":"On-SEF1fdd-Q"},"source":["### Значения для формулы Байеса"]},{"cell_type":"markdown","metadata":{},"source":["Посчитаем необходимые значения для формулы Байеса."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"IwxBHjXYdd-Q"},"outputs":[],"source":["alpha = 1"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"gxsFfXOzdd-Q"},"outputs":[],"source":["Nvoc = len(vocabulary)\n","Pspam = train_data['Label'].value_counts()['spam'] / train_data.shape[0]\n","Pham = train_data['Label'].value_counts()['ham'] / train_data.shape[0]\n","Nspam = train_data.loc[train_data['Label'] == 'spam', 'SMS'].apply(len).sum()\n","Nham = train_data.loc[train_data['Label'] == 'ham', 'SMS'].apply(len).sum()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"jde0BGdPdd-R"},"outputs":[],"source":["def p_w_spam(word):\n","    if word in train_data.columns:\n","        return (train_data.loc[train_data['Label'] == 'spam', word].sum() + alpha) / (Nspam + alpha*Nvoc)\n","    else:\n","        return 1\n","\n","def p_w_ham(word):\n","    if word in train_data.columns:\n","        return (train_data.loc[train_data['Label'] == 'ham', word].sum() + alpha) / (Nham + alpha*Nvoc)\n","    else:\n","        return 1"]},{"cell_type":"markdown","metadata":{"id":"u-nPavNOdd-S"},"source":["### Готовим алгоритм классификации"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Ib39OrM8dd-S"},"outputs":[],"source":["def classify(message):\n","    p_spam_given_message = Pspam\n","    p_ham_given_message = Pham\n","    for word in message:\n","        p_spam_given_message *= p_w_spam(word)\n","        p_ham_given_message *= p_w_ham(word)\n","    if p_ham_given_message > p_spam_given_message:\n","        return 'ham'\n","    elif p_ham_given_message < p_spam_given_message:\n","        return 'spam'\n","    else:\n","        return 'классификация некорректна'"]},{"cell_type":"markdown","metadata":{"id":"7QECGrw8dd-S"},"source":["### Используем тестовые данные"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"dNWXV-5odd-S"},"outputs":[],"source":["test_data['predicted'] = test_data['SMS'].map(classify)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"AejY85XOdd-S","outputId":"112fe436-4d36-42a6-8d3d-8952e282939c","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>spam</td>\n","      <td>[had, your, mobile, 11, months, or, more, u, r...</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>[oh, k, i, m, watching, here]</td>\n","      <td>ham</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Label                                                SMS predicted\n","0   ham  [u, dun, say, so, early, hor, u, c, already, t...       ham\n","1   ham  [nah, i, don, t, think, he, goes, to, usf, he,...       ham\n","2  spam  [freemsg, hey, there, darling, it, s, been, 3,...       ham\n","3  spam  [had, your, mobile, 11, months, or, more, u, r...      spam\n","4   ham                      [oh, k, i, m, watching, here]       ham"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"lNHidizgdd-T"},"outputs":[{"name":"stdout","output_type":"stream","text":["Правильных предсказаний 98.025135 %\n"]}],"source":["correct = (test_data['predicted'] == test_data['Label']).sum() / test_data.shape[0]\n","print(f\"Правильных предсказаний {correct * 100:3f} %\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"-s5NRlJGdd-T","outputId":"de7985cf-9878-486c-ff7a-54295961199e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Label</th>\n","      <th>SMS</th>\n","      <th>predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>[freemsg, hey, there, darling, it, s, been, 3,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>ham</td>\n","      <td>[waiting, for, your, call]</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>182</th>\n","      <td>ham</td>\n","      <td>[26th, of, july]</td>\n","      <td>spam</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>spam</td>\n","      <td>[sms, ac, jsco, energy, is, high, but, u, may,...</td>\n","      <td>ham</td>\n","    </tr>\n","    <tr>\n","      <th>344</th>\n","      <td>ham</td>\n","      <td>[the, last, thing, i, ever, wanted, to, do, wa...</td>\n","      <td>классификация некорректна</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Label                                                SMS   \n","2    spam  [freemsg, hey, there, darling, it, s, been, 3,...  \\\n","96    ham                         [waiting, for, your, call]   \n","182   ham                                   [26th, of, july]   \n","269  spam  [sms, ac, jsco, energy, is, high, but, u, may,...   \n","344   ham  [the, last, thing, i, ever, wanted, to, do, wa...   \n","\n","                     predicted  \n","2                          ham  \n","96                        spam  \n","182                       spam  \n","269                        ham  \n","344  классификация некорректна  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["test_data.loc[test_data['predicted'] != test_data['Label']].head()"]},{"cell_type":"markdown","metadata":{},"source":["# Наивный байесовский классификатор в sklearn\n","Ура, мы реализовали наивный байесовский классификатор с нуля!\n","А теперь посмотрим, как то же самое можно сделать с помощью библиотеки scikit-learn."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"V3xAvBRndd-T"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB"]},{"cell_type":"markdown","metadata":{},"source":["Прочитаем заново csv-файл и предобработаем данные. Разбивать сообщения на слова в этот раз не нужно, мы сделаем это далее с помощью встроенных инструментов"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'SMSSpamCollection.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSMSSpamCollection.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSMS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n","File \u001b[1;32mc:\\Python 3.9.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python 3.9.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Python 3.9.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python 3.9.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Python 3.9.10\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SMSSpamCollection.csv'"]}],"source":["df = pd.read_csv(\n","    \"SMSSpamCollection.csv\", header=None, sep=\"\\t\", names=[\"Label\", \"SMS\"]\n",")\n","\n","df[\"SMS\"] = df[\"SMS\"].str.replace(r\"\\W+\", \" \", regex=True).str.lower()\n","\n","df['SMS'] = df['SMS'].str.replace('\\s+', ' ', regex=True).str.strip()\n","df['SMS'] = df['SMS'].str.lower()\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Преобразуем строки в векторный вид – то есть, снова создадим таблицу с частотами слов. Но в этот раз воспользуемся встроенным в sklearn классов CountVectorizer()."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5572, 8713) (5572,)\n"]}],"source":["vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(df[\"SMS\"])\n","y = df[\"Label\"]\n","\n","print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["С помощью функции `train_test_split` из scikit-learn разобьём выборку на обучающую и тестовую в пропорции 80/20. Не забудем сделать стратификацию!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.979372197309417\n"]}],"source":["clf = MultinomialNB()\n","clf.fit(X_train, y_train)\n","\n","y_test_pred = clf.predict(X_test)\n","\n","print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")"]}],"metadata":{"colab":{"name":"НаивныйБайес.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"vscode":{"interpreter":{"hash":"86c56a74836ad344b00594bf6f38fa6a676a207ceefe20d101fbc465800ccb8d"}}},"nbformat":4,"nbformat_minor":0}
